{"cells":[{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-10-05T13:27:37.292520Z","iopub.status.busy":"2022-10-05T13:27:37.291976Z","iopub.status.idle":"2022-10-05T13:27:37.502556Z","shell.execute_reply":"2022-10-05T13:27:37.501251Z","shell.execute_reply.started":"2022-10-05T13:27:37.292403Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","# This Cell generates the training pictures out of the tif files if needed\n","# For the mini-image generation it is needed to split the images into smaller ones, beacause ram is limited\n","\n","from operator import eq\n","from re import I\n","import numpy as np  # linear algebra\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import PIL\n","from ctypes import cdll\n","from PIL import Image\n","from openslide import OpenSlide\n","PIL.Image.MAX_IMAGE_PIXELS = 2331200000\n","trainingPath: str = '../input/mayo-clinic-strip-ai/train/'\n","testPath: str = '../input/mayo-clinic-strip-ai/test/'\n","generatedTrainingDataPath = '../training-data/'  # label/imgId/sliceNumber\n","trainingDataPathList = ['../training-data/', '../training-data2/', '../training-data3/', '../training-data4/'] # training data will be generated 3 times to get different data for the 3 different models\n","\n","reGenerateTrainingDataLAA = False\n","reGenerateTrainingDataCE = False\n","targetQuantityOfTilesPerFieldLAA = 2200\n","targetQuantityOfTilesPerFieldCE = 600\n","\n","trainingMode = False\n","\n","# load train.csv into pandas dataframe\n","if trainingMode:\n","    trainDataMetaTable = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')\n","\n","\n","def checkInnerTileVariance(imgNDArray, startX, startY, height, width, numberOfSamples, avgDifferenceNeeded, maxAcceptedEquals, equalsDecrementIfUnequal, equalsIncrementIfEqual, maxAbsoluteDifferenceToBeEquals):\n","    # get randome pixels in changing quaters in the tileArea and check the difference between the rgb values\n","    # if the average difference is to small, the image area is not useful (white background for example would not be usefull)\n","    lastPixelRGBValues = imgNDArray[startX, startY]\n","    differenceSum = 0\n","    equalsCount = 0\n","    quaterChangeInterval = int(numberOfSamples / 4)\n","    numberOfSamplesDoneCurrentQuater = 0\n","    halfWidth = int(width / 2)\n","    halfHeight = int(height / 2)\n","    startXOffset = 0\n","    startYOffset = 0\n","    for i in range(numberOfSamples):\n","        startXWithOffset = startX + startXOffset\n","        startYWithOffset = startY + startYOffset\n","        randomX = np.random.randint(startXWithOffset, startXWithOffset + halfWidth)\n","        randomY = np.random.randint(startYWithOffset, startYWithOffset + halfHeight)\n","        currentPixelRGBValues = imgNDArray[randomX, randomY]\n","        differenceAbsolute = abs(int(currentPixelRGBValues[0]) - int(lastPixelRGBValues[0])) + abs(int(\n","            currentPixelRGBValues[1]) - int(lastPixelRGBValues[1])) + abs(int(currentPixelRGBValues[2]) - int(lastPixelRGBValues[2]))\n","        # if the pixels are (almost) the same\n","        if differenceAbsolute <= maxAbsoluteDifferenceToBeEquals:\n","            equalsCount += equalsIncrementIfEqual\n","            if equalsCount > maxAcceptedEquals:\n","                return False\n","        else:\n","            equalsCount -= equalsDecrementIfUnequal\n","        differenceSum += differenceAbsolute\n","        lastPixelRGBValues = currentPixelRGBValues\n","        numberOfSamplesDoneCurrentQuater += 1\n","        if numberOfSamplesDoneCurrentQuater >= quaterChangeInterval:\n","            numberOfSamplesDoneCurrentQuater = 0\n","            if startXOffset == 0:\n","                startXOffset = halfWidth\n","            else:\n","                startXOffset = 0\n","                if startYOffset == 0:\n","                    startYOffset = halfHeight\n","                else:\n","                    startYOffset = 0\n","    return differenceSum / numberOfSamples >= avgDifferenceNeeded\n","\n","\n","def createRandomTilesFromImage(deletePastResults, fieldNumber, imgResultPath, imgNDArray, imgName, numberOfTilesToGenerate, tileWidth, tileHeight,saveTile):\n","    numberOfTilesGenerated = 0\n","    if saveTile:\n","        if deletePastResults:\n","            # remove all files in the folder\n","            if os.path.exists(imgResultPath):\n","                for file in os.listdir(imgResultPath):\n","                    os.remove(os.path.join(imgResultPath, file))\n","        if not os.path.exists(imgResultPath):\n","            os.mkdir(imgResultPath)\n","    maxNumberOfTriesPerTile = 50\n","    # if more than 75% of the current 1/9 of the 3x3 grid is useless, than it should not get that much tiles\n","    maxNumberOfTriesAbsolute = numberOfTilesToGenerate * 4\n","    numberOfTriesDoneCurrentTile = 0\n","    numberOfTriesDoneAbsolute = 0\n","    # the area for the final image is half the tile size (the tile gets reduced and loses some detail information) to get a better overview for the model withouth loosing to much performance while training\n","    generatedTileWidth = int(tileWidth / 2)\n","    generatedTileHeight = int(tileHeight / 2)\n","    generatedTileList = []\n","    while numberOfTilesGenerated < numberOfTilesToGenerate and numberOfTriesDoneCurrentTile < maxNumberOfTriesPerTile and numberOfTriesDoneAbsolute < maxNumberOfTriesAbsolute:\n","        # get random coordinates\n","        startX = np.random.randint(0, imgNDArray.shape[0] - tileWidth)\n","        startY = np.random.randint(0, imgNDArray.shape[1] - tileHeight)\n","        numberOfTriesDoneCurrentTile += 1\n","        numberOfTriesDoneAbsolute += 1\n","        # check if the tile is usefull\n","        if checkInnerTileVariance(imgNDArray=imgNDArray, startX=startX, startY=startY, height=tileHeight, width=tileWidth, numberOfSamples=200, avgDifferenceNeeded=128, maxAcceptedEquals=20, equalsDecrementIfUnequal=1, equalsIncrementIfEqual=2, maxAbsoluteDifferenceToBeEquals=8):\n","            # write every second pixel to a new image\n","            generatedTile: Image = Image.new(\n","                'RGB', (generatedTileWidth, generatedTileHeight))\n","            for x in range(generatedTileWidth):\n","                for y in range(generatedTileHeight):\n","                    # put pixel withouth alpha channel\n","                    currentPixel = imgNDArray[startX + x * 2, startY + y * 2]\n","                    generatedTile.putpixel(\n","                        (x, y), (currentPixel[0], currentPixel[1], currentPixel[2]))\n","            # save the image\n","            if saveTile:\n","                generatedTile.save(\n","                    imgResultPath + 'fieldNumber' + str(fieldNumber)+'_' + 'tileNumber' + str(numberOfTilesGenerated) + '.tif') #used for training\n","            else:\n","                generatedTileList.append(np.array(generatedTile)) #used for testing\n","            numberOfTilesGenerated += 1\n","            numberOfTriesDoneCurrentTile = 0\n","    return generatedTileList\n","\n","\n","def imageSplittingAndTileGeneration(imageId, imageFolder, imgLabel, saveTile, optionalNumberOfTilesToGeneratePerField = 0 , tileListToFill = []):\n","    # fields are parts of the 3x3 grid the images get split into (this is done due to memory limitations)\n","    # tiles are randome but usefull parts of the fields (the tiles are the training data or the test data)\n","    # open the image\n","    slide = OpenSlide(imageFolder + imageId + '.tif')\n","    # get the image size\n","    width, height = slide.dimensions\n","    # slice the images into 3x3 tiles\n","    if height < 200:\n","        return tileListToFill\n","    if width < 200:\n","        return tileListToFill\n","    fieldCount = 0\n","    numberOfRows = (int)(height / 16000) + 1\n","    numberOfColumns = (int)(width / 16000) + 1\n","    numberOfFields = numberOfRows * numberOfColumns\n","    # create numberOftilesToGenerate depending on targetQuantityOfTilesPerFieldLAA and targetQuantityOfTilesPerFieldCE depends on label\n","    numberOfTilesToGeneratePerField = 0\n","    if imgLabel == 'LAA':\n","        numberOfTilesToGeneratePerField = targetQuantityOfTilesPerFieldLAA\n","    else:\n","        numberOfTilesToGeneratePerField = targetQuantityOfTilesPerFieldCE\n","    if optionalNumberOfTilesToGeneratePerField > 0:\n","        numberOfTilesToGeneratePerField = optionalNumberOfTilesToGeneratePerField\n","    # get the tile size\n","    fieldWidth = int(width / numberOfColumns)\n","    fieldHeight = int(height / numberOfRows)\n","    for i in range(0, numberOfRows):\n","        for j in range(0, numberOfColumns):\n","            imgName = imageId\n","            # get the tile\n","            field = slide.read_region(\n","                (i * fieldWidth, j * fieldHeight), 0, (fieldWidth, fieldHeight))\n","            # convert the tile to a numpy array\n","            field = np.array(field)\n","            if imgLabel is not None:\n","                # try generate 300 tiles from the field\n","                tiles = createRandomTilesFromImage(deletePastResults = (fieldCount == 0), fieldNumber=fieldCount, imgResultPath=generatedTrainingDataPath +\n","                                           imgLabel + '/' + imgName + '/', imgNDArray=field, imgName=imgName, numberOfTilesToGenerate=numberOfTilesToGeneratePerField, tileWidth=160, tileHeight=160, saveTile=saveTile)\n","                tileListToFill.extend(tiles)\n","            fieldCount += 1\n","            print('fieldCount: ' + str(fieldCount) + ' of ' + str(numberOfFields) + ' for image ' + imageId + ' done')\n","    return tileListToFill\n","\n","\n","def generateTrainingData():\n","    # iterate through all tif files in '../input/train/' and create 300 tiles for each image\n","    # iterate through the rows of the dataframe\n","    for index, row in trainDataMetaTable.iterrows():\n","        # get the image_id\n","        imageId = row['image_id']\n","        # get the image_label\n","        imageLabel = row['label']\n","        if (imageLabel == 'CE' and not reGenerateTrainingDataCE) or (imageLabel == 'LAA' and not reGenerateTrainingDataLAA):\n","            continue\n","        # check if the image exists\n","        if os.path.exists(trainingPath + imageId + '.tif'):\n","            imageSplittingAndTileGeneration(imageId, trainingPath, imageLabel, True)\n","        else:\n","            print('image ' + imageId + ' does not exist')\n","        # print the image number done\n","        print('image ' + str(index) + ' done')\n","\n","# check if the training data is already generated\n","if trainingMode:\n","    for trainingDataPath in trainingDataPathList:\n","        generatedTestDataPath = trainingDataPath\n","        numberOfExistingTrainingImageFoldersSufficentCE = False\n","        numberOfExistingTrainingImageFoldersSufficentLAA = False\n","        if os.path.exists(generatedTrainingDataPath):\n","            numberOfExistingTrainingImageFoldersCE = len(\n","                os.listdir(generatedTrainingDataPath + '/CE/')) \n","            numberOfExistingTrainingImageFoldersLAA =  len(os.listdir(generatedTrainingDataPath + '/LAA/'))\n","            numberOfExistingTrainingImageFoldersSufficentLAA = int(\n","                numberOfExistingTrainingImageFoldersLAA * 1.1) >= len(trainDataMetaTable[trainDataMetaTable['label'] == 'LAA'])\n","            numberOfExistingTrainingImageFoldersSufficentCE = int(\n","                numberOfExistingTrainingImageFoldersCE * 1.1) >= len(trainDataMetaTable[trainDataMetaTable['label'] == 'CE'])\n","        else:\n","            os.mkdir(generatedTrainingDataPath)\n","            os.mkdir(generatedTrainingDataPath + '/CE/')\n","            os.mkdir(generatedTrainingDataPath + '/LAA/')\n","        if not numberOfExistingTrainingImageFoldersSufficentLAA:\n","            reGenerateTrainingDataLAA = True\n","        if not numberOfExistingTrainingImageFoldersSufficentCE:\n","            reGenerateTrainingDataCE = True\n","        if reGenerateTrainingDataLAA or reGenerateTrainingDataCE:\n","            generateTrainingData()\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-10-05T13:27:37.505245Z","iopub.status.busy":"2022-10-05T13:27:37.504853Z","iopub.status.idle":"2022-10-05T13:27:55.910138Z","shell.execute_reply":"2022-10-05T13:27:55.908553Z","shell.execute_reply.started":"2022-10-05T13:27:37.505211Z"},"trusted":true},"outputs":[],"source":["#this cell creates, loads or trains the basic models wich are used for Monte-Carlo-Predicitions on multiple different randome samples of the image\n","# import keras\n","import random\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n","from tensorflow.keras.optimizers import Adam\n","\n","basicModelPath = '../input/basicmodels4/'\n","logLossEvaluationModelPath = '../input/losslogevaluationmodel5/'\n","#logLossEvaluationModelPath = ''\n","useTrainingDataPath =  '../training-data/'\n","trainingDataFoldersLAA = []\n","trainingDataFoldersCE = []\n","trainingDataFoldersContent = {}\n","numberOfTrainingSamplesPerIteration = 2048\n","numberOfInputImagesForOneModel = 4\n","numberOfClasses = 2\n","CE_INDEX = 0\n","LAA_INDEX = 1\n","if trainingMode:\n","    accumulatedData = np.zeros(\n","    (numberOfTrainingSamplesPerIteration, numberOfInputImagesForOneModel, 80, 80, 3), dtype=float)\n","    accumulatedLabels = np.zeros((numberOfTrainingSamplesPerIteration,numberOfClasses), dtype=float)\n","\n","dataLoadingFolderSuccessMinimumFactorModelList = [0.62, 0.2, 0.4]\n","dataLoadingFolderSuccessMinimumFactor = 0.60 # if more than 40% of training data folders/images are failing, cause of repeating data, the training is stopped, this protects against overfitting while making efficient use of randomly loaded training data\n","dataLoadingFolderSuccessInflationFactor = 0.9901\n","newDataLoadingSuccess = 1.0\n","\n","#dictionary\n","pictureUsageCheckDictionary = {} #this dictionary gets filled with picture names as keys and boolean values as values, where True means the picture got already used for the input-picture-number corresponding to the index of the models input pictures.\n","\n","def createModelType1():\n","    # create the model\n","    inputLayer = keras.Input(shape=(numberOfInputImagesForOneModel, 80, 80, 3))\n","    conv1 = Conv2D(32, kernel_size=(3, 3), strides=(2, 2), activation='relu')(inputLayer)\n","    conv2 = Conv2D(128, kernel_size=(4, 4), strides=(2, 2), activation='relu')(conv1)\n","    conv3 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), activation='relu')(conv2)\n","    conv4 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), activation='relu')(conv3)\n","    flatten = Flatten()(conv4)\n","    dense1 = Dense(4096, activation='relu')(flatten)\n","    dense2 = Dense(2048, activation='relu')(dense1)\n","    dense3 = Dense(1024, activation='relu')(dense2)\n","    dense4 = Dense(512, activation='relu')(dense3)\n","    dense5 = Dense(128, activation='relu')(dense4)\n","    outputLayer = Dense(2, activation='sigmoid')(dense5)\n","    model = keras.Model(inputs=inputLayer, outputs=outputLayer)\n","    # compile the model\n","    model.compile(\n","        optimizer=Adam(lr=0.00005),\n","        loss='mse',\n","        metrics=['accuracy','categorical_accuracy']\n","    )\n","    return model # this model is designed to be trained on 4 images at once, the advantage lies in the fact that the model can learn to recognize patterns in the images, which are not present in the single images, but are present in the combination of the images\n","\n","def createModelType2(): #model2 trys compensate the mistakes of model1a and model1b\n","    # create convolutional model with functional api\n","    inputLayer = keras.Input(shape=(numberOfInputImagesForOneModel, 80, 80, 3))\n","    conv1 = Conv2D(32, kernel_size=(3, 3), strides=(2, 2), activation='relu')(inputLayer)\n","    conv2 = Conv2D(128, kernel_size=(4, 4), strides=(2, 2), activation='relu')(conv1)\n","    conv3 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), activation='relu')(conv2)\n","    conv4 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), activation='relu')(conv3)\n","    flatten = Flatten()(conv4)\n","    #add concat additional feature with 512 inputs to flatten\n","    inputLayer2 = keras.Input(shape=(4)) #the last layer of model1a.h5 and model1b.h5 are concatenated to this layer\n","    concat = keras.layers.concatenate([flatten, inputLayer2])\n","    dense1 = Dense(5000, activation='relu')(concat) \n","    dense2 = Dense(2500, activation='relu')(dense1)\n","    dense3 = Dense(1250, activation='relu')(dense2)\n","    dense4 = Dense(1250, activation='relu')(dense3)\n","    dense5 = Dense(512, activation='relu')(dense4)\n","    dense6 = Dense(128, activation='relu')(dense5)\n","    outputLayer = Dense(2, activation='sigmoid')(dense6)\n","    model = keras.Model(inputs=[inputLayer, inputLayer2], outputs=outputLayer)\n","    # compile the model\n","    model.compile(\n","        optimizer=Adam(lr=0.00005),\n","        loss='mse',\n","        metrics=['accuracy','categorical_accuracy']\n","    )\n","    return model # this model is designed to be trained on 4 images at once, the advantage lies in the fact that the model can learn to recognize patterns in the images, which are not present in the single images, but are present in the combination of the images\n","    \n","\n","def loadTrainingDataFolders(trainingDataPath):\n","    global trainingDataFoldersLAA\n","    global trainingDataFoldersCE\n","    global trainingDataFoldersContent\n","    trainingDataFoldersLAA.clear()\n","    trainingDataFoldersCE.clear()\n","\n","    for folder in os.listdir(trainingDataPath + '/CE/'):\n","        if len(os.listdir(trainingDataPath + '/CE/' + folder)) < numberOfInputImagesForOneModel:\n","            continue\n","        trainingDataFoldersCE.append(trainingDataPath + 'CE/' + folder + '/')\n","    for folder in os.listdir(trainingDataPath + '/LAA/'):\n","        # check if the folder is empty\n","        if len(os.listdir(trainingDataPath + '/LAA/' + folder)) < numberOfInputImagesForOneModel:\n","            continue\n","        trainingDataFoldersLAA.append(trainingDataPath + 'LAA/' + folder + '/')\n","\n","    # load the content paths of the training data folders\n","    for folder in trainingDataFoldersLAA:\n","        trainingDataFoldersContent[folder] = []\n","        for file in os.listdir(folder):\n","            trainingDataFoldersContent[folder].append(folder + file)\n","    for folder in trainingDataFoldersCE:\n","        trainingDataFoldersContent[folder] = []\n","        for file in os.listdir(folder):\n","            trainingDataFoldersContent[folder].append(folder + file)\n","    \n","\n","def loadTrainingData():\n","    global accumulatedData\n","    global accumulatedLabels\n","    global pictureUsageCheckDictionary\n","    global newDataLoadingSuccess\n","    nextIsCE = True\n","    maxNumberOfInFolderFails = 3\n","    newDataLoadingSuccess = 1.0\n","    dataLoadingFolderAdditionOnSuccess = 0.01\n","    # load the data\n","    # iterate through the rows of the dataframe\n","    i = 0\n","    while i < numberOfTrainingSamplesPerIteration:\n","        # choose random image folder\n","        if nextIsCE:\n","            folder = random.choice(trainingDataFoldersCE)\n","        else:\n","            folder = random.choice(trainingDataFoldersLAA)\n","        numberOfFailsCounter = 0\n","        inputImageNumber = 0\n","        folderFailed = False\n","        #get 4 random images from the folder\n","        while inputImageNumber < numberOfInputImagesForOneModel:\n","            #choose random image\n","            imagePath = random.choice(trainingDataFoldersContent[folder])\n","            usageList = pictureUsageCheckDictionary.get(imagePath)\n","            if usageList == None:\n","                usageList = [False] * numberOfInputImagesForOneModel\n","                pictureUsageCheckDictionary[imagePath] = usageList\n","            if not usageList[inputImageNumber]:\n","                usageList[inputImageNumber] = True\n","                # use PIL to load the image\n","                img = Image.open(imagePath)\n","                # load the image into a numpy array\n","                img = np.array(img, dtype=float)\n","                #normalize the image\n","                img *= 1.0 / 255.0\n","                # add the image to the accumulated data\n","                accumulatedData[i][inputImageNumber] = img\n","                inputImageNumber += 1\n","            else:\n","                numberOfFailsCounter += 1\n","                if numberOfFailsCounter > maxNumberOfInFolderFails:\n","                    folderFailed = True\n","                    break\n","        if not folderFailed:\n","            # add the label to the labels\n","            if nextIsCE:\n","                accumulatedLabels[i][CE_INDEX] = 1.0\n","                accumulatedLabels[i][LAA_INDEX] = 0.0\n","            else:\n","                accumulatedLabels[i][LAA_INDEX] = 1.0\n","                accumulatedLabels[i][CE_INDEX] = 0.0\n","            nextIsCE = not nextIsCE\n","            i += 1\n","            newDataLoadingSuccess += dataLoadingFolderAdditionOnSuccess\n","        newDataLoadingSuccess *= dataLoadingFolderSuccessInflationFactor\n","        if newDataLoadingSuccess < dataLoadingFolderSuccessMinimumFactor:\n","            print(\"Not enough new training data, stopping training\")\n","            break\n","    return newDataLoadingSuccess >= dataLoadingFolderSuccessMinimumFactor\n","\n","def trainModelType1():\n","    # create the model\n","    model = createModelType1()\n","    # load the training data folders\n","    loadTrainingDataFolders(useTrainingDataPath)\n","    # train the model\n","    iterationCount = 0\n","    while loadTrainingData():\n","        model.fit(accumulatedData, accumulatedLabels, epochs=1, batch_size=16)\n","        iterationCount += 1\n","        # print count and successweight\n","        print(\"Iteration: \" + str(iterationCount) + \" new data loading success: \" + str(newDataLoadingSuccess))\n","    return model\n","\n","def trainModelType2(model1a, model1b):\n","    # create the model\n","    model = createModelType2()\n","    # load the training data folders\n","    loadTrainingDataFolders(useTrainingDataPath)\n","    # train the model\n","    iterationCount = 0\n","    while loadTrainingData():\n","        # get the outputs of the models\n","        model1aOutput = model1a.predict(accumulatedData)\n","        model1bOutput = model1b.predict(accumulatedData)\n","        # concatenate the outputs\n","        model2Input = np.concatenate((model1aOutput, model1bOutput), axis=1)\n","        # train the model\n","        model.fit([accumulatedData, model2Input], accumulatedLabels, epochs=1, batch_size=16)\n","        iterationCount += 1\n","        # print count and successweight\n","        print(\"Iteration: \" + str(iterationCount) + \" new data loading success: \" + str(newDataLoadingSuccess))\n","    return model\n","\n","def loadModel(modelPath):\n","    # load the model\n","    model = keras.models.load_model(modelPath)\n","    return model\n","\n","\n","# check if model1a.h5 exists, load it else train it\n","if os.path.isfile(basicModelPath + 'model1a.h5'):\n","    model1a = loadModel(basicModelPath + 'model1a.h5')\n","elif trainingMode:\n","    useTrainingDataPath = trainingDataPathList[0]\n","    dataLoadingFolderSuccessMinimumFactor = dataLoadingFolderSuccessMinimumFactorModelList[0]\n","    model1a = trainModelType1()\n","    model1a.save('model1a.h5')\n","else:\n","    print(\"No model1a.h5 found, stopping\")\n","    exit()\n","# check if model1b.h5 exists, load it else train it\n","if os.path.isfile(basicModelPath + 'model1b.h5'):\n","    model1b = loadModel(basicModelPath + 'model1b.h5')\n","elif trainingMode:\n","    useTrainingDataPath = trainingDataPathList[1]\n","    dataLoadingFolderSuccessMinimumFactor = dataLoadingFolderSuccessMinimumFactorModelList[1]\n","    model1b = trainModelType1()\n","    model1b.save('model1b.h5')\n","else:\n","    print(\"No model1b.h5 found, stopping\")\n","    exit()\n","# check if model2.h5 exists, load it else train it\n","if os.path.isfile(basicModelPath + 'model2.h5'):\n","    model2 = loadModel(basicModelPath + 'model2.h5')\n","elif trainingMode:\n","    useTrainingDataPath = trainingDataPathList[2]\n","    dataLoadingFolderSuccessMinimumFactor = dataLoadingFolderSuccessMinimumFactorModelList[2]\n","    model2 = trainModelType2(model1a, model1b)\n","    model2.save('model2.h5')\n","else:\n","    print(\"No model2.h5 found, stopping\")\n","    exit()\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-10-05T13:27:55.915886Z","iopub.status.busy":"2022-10-05T13:27:55.914653Z","iopub.status.idle":"2022-10-05T13:32:40.557149Z","shell.execute_reply":"2022-10-05T13:32:40.554879Z","shell.execute_reply.started":"2022-10-05T13:27:55.915837Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fieldCount: 1 of 2 for image 008e5c_0 done\n","fieldCount: 2 of 2 for image 008e5c_0 done\n","fieldCount: 1 of 4 for image 00c058_0 done\n","fieldCount: 2 of 4 for image 00c058_0 done\n","fieldCount: 1 of 12 for image 006388_0 done\n","WARNING:tensorflow:5 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F16AB53D38> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","image 008e5c_0 done!\n","fieldCount: 3 of 4 for image 00c058_0 done\n","fieldCount: 4 of 4 for image 00c058_0 done\n","image 00c058_0 done!\n","fieldCount: 2 of 12 for image 006388_0 done\n","fieldCount: 1 of 1 for image 026c97_0 done\n","image 026c97_0 done!\n","fieldCount: 1 of 8 for image 01adc5_0 done\n","fieldCount: 1 of 18 for image 028989_0 done\n","fieldCount: 3 of 12 for image 006388_0 done\n","fieldCount: 2 of 8 for image 01adc5_0 done\n","fieldCount: 3 of 8 for image 01adc5_0 done\n","fieldCount: 4 of 8 for image 01adc5_0 done\n","fieldCount: 2 of 18 for image 028989_0 done\n","fieldCount: 4 of 12 for image 006388_0 done\n","fieldCount: 5 of 8 for image 01adc5_0 done\n","fieldCount: 3 of 18 for image 028989_0 done\n","fieldCount: 5 of 12 for image 006388_0 done\n","fieldCount: 6 of 8 for image 01adc5_0 done\n","fieldCount: 7 of 8 for image 01adc5_0 done\n","fieldCount: 4 of 18 for image 028989_0 done\n","fieldCount: 8 of 8 for image 01adc5_0 done\n","image 01adc5_0 done!\n","fieldCount: 1 of 9 for image 029c68_0 done\n","fieldCount: 5 of 18 for image 028989_0 done\n","fieldCount: 6 of 12 for image 006388_0 done\n","fieldCount: 2 of 9 for image 029c68_0 done\n","fieldCount: 6 of 18 for image 028989_0 done\n","fieldCount: 3 of 9 for image 029c68_0 done\n","fieldCount: 7 of 12 for image 006388_0 done\n","fieldCount: 4 of 9 for image 029c68_0 done\n","fieldCount: 7 of 18 for image 028989_0 done\n","fieldCount: 8 of 12 for image 006388_0 done\n","fieldCount: 8 of 18 for image 028989_0 done\n","fieldCount: 5 of 9 for image 029c68_0 done\n","fieldCount: 9 of 18 for image 028989_0 done\n","fieldCount: 10 of 18 for image 028989_0 done\n","fieldCount: 9 of 12 for image 006388_0 done\n","fieldCount: 11 of 18 for image 028989_0 done\n","fieldCount: 10 of 12 for image 006388_0 done\n","fieldCount: 12 of 18 for image 028989_0 done\n","fieldCount: 11 of 12 for image 006388_0 done\n","fieldCount: 6 of 9 for image 029c68_0 done\n","fieldCount: 13 of 18 for image 028989_0 done\n","fieldCount: 12 of 12 for image 006388_0 done\n","fieldCount: 14 of 18 for image 028989_0 done\n","image 006388_0 done!\n","fieldCount: 15 of 18 for image 028989_0 done\n","fieldCount: 7 of 9 for image 029c68_0 done\n","fieldCount: 16 of 18 for image 028989_0 done\n","fieldCount: 17 of 18 for image 028989_0 done\n","fieldCount: 18 of 18 for image 028989_0 done\n","fieldCount: 1 of 2 for image 032f10_0 done\n","fieldCount: 2 of 2 for image 032f10_0 done\n","fieldCount: 8 of 9 for image 029c68_0 done\n","image 028989_0 done!\n","image 032f10_0 done!\n","fieldCount: 1 of 2 for image 0372b0_0 done\n","fieldCount: 2 of 2 for image 0372b0_0 done\n","fieldCount: 9 of 9 for image 029c68_0 done\n","image 0372b0_0 done!\n","image 029c68_0 done!\n","fieldCount: 1 of 10 for image 037300_0 done\n","fieldCount: 1 of 4 for image 03d1ec_0 done\n","fieldCount: 1 of 2 for image 03e6b7_0 done\n","fieldCount: 2 of 2 for image 03e6b7_0 done\n","image 03e6b7_0 done!\n","fieldCount: 2 of 10 for image 037300_0 done\n","fieldCount: 2 of 4 for image 03d1ec_0 done\n","fieldCount: 3 of 10 for image 037300_0 done\n","fieldCount: 1 of 16 for image 0415c3_0 done\n","fieldCount: 3 of 4 for image 03d1ec_0 done\n","fieldCount: 4 of 10 for image 037300_0 done\n","fieldCount: 4 of 4 for image 03d1ec_0 done\n","fieldCount: 2 of 16 for image 0415c3_0 done\n","fieldCount: 5 of 10 for image 037300_0 done\n","image 03d1ec_0 done!\n","fieldCount: 6 of 10 for image 037300_0 done\n","fieldCount: 7 of 10 for image 037300_0 done\n","fieldCount: 8 of 10 for image 037300_0 done\n","fieldCount: 9 of 10 for image 037300_0 done\n","fieldCount: 1 of 6 for image 04439c_0 done\n","fieldCount: 10 of 10 for image 037300_0 done\n","image 037300_0 done!\n","fieldCount: 3 of 16 for image 0415c3_0 done\n","fieldCount: 2 of 6 for image 04439c_0 done\n","fieldCount: 1 of 6 for image 045eb0_0 done\n","fieldCount: 4 of 16 for image 0415c3_0 done\n","fieldCount: 2 of 6 for image 045eb0_0 done\n","fieldCount: 3 of 6 for image 04439c_0 done\n","fieldCount: 5 of 16 for image 0415c3_0 done\n","fieldCount: 6 of 16 for image 0415c3_0 done\n","fieldCount: 4 of 6 for image 04439c_0 done\n","fieldCount: 7 of 16 for image 0415c3_0 done\n","fieldCount: 3 of 6 for image 045eb0_0 done\n","fieldCount: 5 of 6 for image 04439c_0 done\n","fieldCount: 8 of 16 for image 0415c3_0 done\n","fieldCount: 6 of 6 for image 04439c_0 done\n","fieldCount: 9 of 16 for image 0415c3_0 done\n","fieldCount: 4 of 6 for image 045eb0_0 doneimage 04439c_0 done!\n","\n","fieldCount: 10 of 16 for image 0415c3_0 donefieldCount: 5 of 6 for image 045eb0_0 done\n","\n","fieldCount: 6 of 6 for image 045eb0_0 done\n","image 045eb0_0 done!\n","fieldCount: 11 of 16 for image 0415c3_0 done\n","fieldCount: 12 of 16 for image 0415c3_0 done\n","fieldCount: 13 of 16 for image 0415c3_0 done\n","fieldCount: 1 of 6 for image 0468a8_0 done\n","fieldCount: 1 of 9 for image 0468a8_1 done\n","fieldCount: 14 of 16 for image 0415c3_0 done\n","fieldCount: 15 of 16 for image 0415c3_0 done\n","fieldCount: 16 of 16 for image 0415c3_0 done\n","image 0415c3_0 done!\n","fieldCount: 2 of 6 for image 0468a8_0 done\n","fieldCount: 2 of 9 for image 0468a8_1 done\n","fieldCount: 1 of 4 for image 049194_0 done\n","fieldCount: 3 of 9 for image 0468a8_1 done\n","fieldCount: 3 of 6 for image 0468a8_0 done\n","fieldCount: 2 of 4 for image 049194_0 done\n","fieldCount: 4 of 6 for image 0468a8_0 done\n","fieldCount: 5 of 6 for image 0468a8_0 done\n","fieldCount: 6 of 6 for image 0468a8_0 done\n","fieldCount: 4 of 9 for image 0468a8_1 done\n","fieldCount: 3 of 4 for image 049194_0 done\n","image 0468a8_0 done!\n","fieldCount: 1 of 8 for image 049194_1 done\n","fieldCount: 5 of 9 for image 0468a8_1 done\n","fieldCount: 4 of 4 for image 049194_0 done\n","image 049194_0 done!\n","fieldCount: 2 of 8 for image 049194_1 done\n","fieldCount: 1 of 6 for image 04f7a4_0 done\n","fieldCount: 2 of 6 for image 04f7a4_0 done\n","fieldCount: 3 of 8 for image 049194_1 done\n","fieldCount: 6 of 9 for image 0468a8_1 done\n","fieldCount: 3 of 6 for image 04f7a4_0 done\n","fieldCount: 4 of 8 for image 049194_1 done\n","fieldCount: 5 of 8 for image 049194_1 done\n","fieldCount: 6 of 8 for image 049194_1 done\n","fieldCount: 4 of 6 for image 04f7a4_0 done\n","fieldCount: 7 of 8 for image 049194_1 done\n","fieldCount: 5 of 6 for image 04f7a4_0 done\n","fieldCount: 8 of 8 for image 049194_1 done\n","fieldCount: 6 of 6 for image 04f7a4_0 done\n","fieldCount: 7 of 9 for image 0468a8_1 done\n","image 049194_1 done!\n","image 04f7a4_0 done!\n","fieldCount: 1 of 6 for image 055f6a_0 done\n","fieldCount: 8 of 9 for image 0468a8_1 done\n","fieldCount: 1 of 6 for image 05a1ec_0 done\n","fieldCount: 2 of 6 for image 055f6a_0 done\n","fieldCount: 3 of 6 for image 055f6a_0 done\n","fieldCount: 9 of 9 for image 0468a8_1 done\n","fieldCount: 2 of 6 for image 05a1ec_0 done\n","image 0468a8_1 done!\n","fieldCount: 4 of 6 for image 055f6a_0 done\n","fieldCount: 5 of 6 for image 055f6a_0 done\n","fieldCount: 6 of 6 for image 055f6a_0 done\n","image 055f6a_0 done!\n","fieldCount: 3 of 6 for image 05a1ec_0 done\n","fieldCount: 1 of 10 for image 062387_0 done\n","fieldCount: 1 of 2 for image 070fe0_0 done\n","fieldCount: 2 of 2 for image 070fe0_0 done\n","fieldCount: 4 of 6 for image 05a1ec_0 done\n","fieldCount: 2 of 10 for image 062387_0 done\n","fieldCount: 5 of 6 for image 05a1ec_0 done\n","image 070fe0_0 done!\n","fieldCount: 6 of 6 for image 05a1ec_0 done\n","image 05a1ec_0 done!\n","fieldCount: 3 of 10 for image 062387_0 done\n","fieldCount: 1 of 1 for image 08d3d8_0 done\n","fieldCount: 1 of 3 for image 09644e_0 done\n","fieldCount: 4 of 10 for image 062387_0 done\n","fieldCount: 2 of 3 for image 09644e_0 done\n","fieldCount: 5 of 10 for image 062387_0 done\n","fieldCount: 3 of 3 for image 09644e_0 done\n","fieldCount: 6 of 10 for image 062387_0 done\n","image 08d3d8_0 done!\n","fieldCount: 7 of 10 for image 062387_0 done\n","image 09644e_0 done!\n","fieldCount: 8 of 10 for image 062387_0 done\n","fieldCount: 9 of 10 for image 062387_0 done\n","fieldCount: 10 of 10 for image 062387_0 done\n","image 062387_0 done!\n","fieldCount: 1 of 4 for image 09644e_2 done\n","fieldCount: 1 of 6 for image 09644e_1 done\n","fieldCount: 1 of 6 for image 09644e_3 done\n","fieldCount: 2 of 4 for image 09644e_2 done\n","fieldCount: 2 of 6 for image 09644e_1 done\n","fieldCount: 2 of 6 for image 09644e_3 done\n","fieldCount: 3 of 4 for image 09644e_2 done\n","fieldCount: 3 of 6 for image 09644e_1 done\n","fieldCount: 3 of 6 for image 09644e_3 done\n","fieldCount: 4 of 4 for image 09644e_2 done\n","fieldCount: 4 of 6 for image 09644e_1 done\n","image 09644e_2 done!\n","fieldCount: 5 of 6 for image 09644e_1 done\n","fieldCount: 6 of 6 for image 09644e_1 done\n","fieldCount: 4 of 6 for image 09644e_3 done\n","image 09644e_1 done!\n","fieldCount: 5 of 6 for image 09644e_3 done\n","fieldCount: 1 of 2 for image 09644e_4 done\n","fieldCount: 6 of 6 for image 09644e_3 done\n","fieldCount: 2 of 2 for image 09644e_4 done\n","image 09644e_3 done!\n","fieldCount: 1 of 4 for image 098f15_0 done\n","image 09644e_4 done!\n","fieldCount: 2 of 4 for image 098f15_0 done\n","fieldCount: 1 of 6 for image 0a3ad1_0 done\n","fieldCount: 3 of 4 for image 098f15_0 done\n","fieldCount: 1 of 12 for image 0a47c9_0 done\n","fieldCount: 2 of 6 for image 0a3ad1_0 done\n","fieldCount: 4 of 4 for image 098f15_0 done\n","image 098f15_0 done!\n","fieldCount: 3 of 6 for image 0a3ad1_0 done\n","fieldCount: 1 of 4 for image 0aaeb3_0 done\n","fieldCount: 2 of 12 for image 0a47c9_0 done\n","fieldCount: 4 of 6 for image 0a3ad1_0 done\n","fieldCount: 5 of 6 for image 0a3ad1_0 done\n","fieldCount: 6 of 6 for image 0a3ad1_0 done\n","fieldCount: 2 of 4 for image 0aaeb3_0 done\n","image 0a3ad1_0 done!\n","fieldCount: 3 of 12 for image 0a47c9_0 done\n","fieldCount: 1 of 2 for image 0aff58_0 done\n","fieldCount: 2 of 2 for image 0aff58_0 done\n","fieldCount: 3 of 4 for image 0aaeb3_0 done\n","image 0aff58_0 done!\n","fieldCount: 4 of 4 for image 0aaeb3_0 done\n","fieldCount: 1 of 3 for image 0b25f8_0 done\n","fieldCount: 4 of 12 for image 0a47c9_0 done\n","fieldCount: 2 of 3 for image 0b25f8_0 done\n","image 0aaeb3_0 done!\n","fieldCount: 3 of 3 for image 0b25f8_0 done\n","image 0b25f8_0 done!\n","fieldCount: 5 of 12 for image 0a47c9_0 done\n","fieldCount: 1 of 6 for image 0b7871_1 done\n","fieldCount: 1 of 4 for image 0b7871_0 done\n","fieldCount: 2 of 4 for image 0b7871_0 done\n","fieldCount: 2 of 6 for image 0b7871_1 done\n","fieldCount: 6 of 12 for image 0a47c9_0 done\n","fieldCount: 3 of 6 for image 0b7871_1 done\n","fieldCount: 7 of 12 for image 0a47c9_0 done\n","fieldCount: 3 of 4 for image 0b7871_0 done\n","fieldCount: 4 of 6 for image 0b7871_1 done\n","fieldCount: 5 of 6 for image 0b7871_1 done\n","fieldCount: 6 of 6 for image 0b7871_1 done\n","fieldCount: 8 of 12 for image 0a47c9_0 done\n","fieldCount: 4 of 4 for image 0b7871_0 done\n","image 0b7871_1 done!\n","image 0b7871_0 done!\n","fieldCount: 1 of 1 for image 0b7cc8_0 done\n","fieldCount: 9 of 12 for image 0a47c9_0 done\n","fieldCount: 1 of 12 for image 0ba49d_0 done\n","fieldCount: 10 of 12 for image 0a47c9_0 done\n","image 0b7cc8_0 done!\n","fieldCount: 11 of 12 for image 0a47c9_0 done\n","fieldCount: 12 of 12 for image 0a47c9_0 done\n","fieldCount: 2 of 12 for image 0ba49d_0 done\n","image 0a47c9_0 done!\n","fieldCount: 1 of 3 for image 0bd414_0 done\n","fieldCount: 2 of 3 for image 0bd414_0 done\n","fieldCount: 3 of 3 for image 0bd414_0 done\n","fieldCount: 3 of 12 for image 0ba49d_0 done\n","fieldCount: 1 of 12 for image 0bddf9_0 done\n","image 0bd414_0 done!\n","fieldCount: 1 of 6 for image 0c60b8_0 done\n","fieldCount: 2 of 12 for image 0bddf9_0 done\n","fieldCount: 3 of 12 for image 0bddf9_0 done\n","fieldCount: 4 of 12 for image 0ba49d_0 done\n","fieldCount: 4 of 12 for image 0bddf9_0 done\n","fieldCount: 2 of 6 for image 0c60b8_0 done\n","fieldCount: 5 of 12 for image 0ba49d_0 done\n","fieldCount: 5 of 12 for image 0bddf9_0 done\n","fieldCount: 6 of 12 for image 0ba49d_0 done\n","fieldCount: 6 of 12 for image 0bddf9_0 done\n","fieldCount: 3 of 6 for image 0c60b8_0 done\n","fieldCount: 7 of 12 for image 0ba49d_0 done\n","fieldCount: 8 of 12 for image 0ba49d_0 done\n","fieldCount: 9 of 12 for image 0ba49d_0 done\n","fieldCount: 10 of 12 for image 0ba49d_0 done\n","fieldCount: 7 of 12 for image 0bddf9_0 done\n","fieldCount: 4 of 6 for image 0c60b8_0 done\n","fieldCount: 11 of 12 for image 0ba49d_0 done\n","fieldCount: 5 of 6 for image 0c60b8_0 done\n","fieldCount: 12 of 12 for image 0ba49d_0 done\n","fieldCount: 6 of 6 for image 0c60b8_0 done\n","image 0ba49d_0 done!\n","fieldCount: 8 of 12 for image 0bddf9_0 done\n","image 0c60b8_0 done!\n","fieldCount: 9 of 12 for image 0bddf9_0 done\n","fieldCount: 10 of 12 for image 0bddf9_0 done\n","fieldCount: 11 of 12 for image 0bddf9_0 done\n","fieldCount: 12 of 12 for image 0bddf9_0 done\n","fieldCount: 1 of 1 for image 0cc0bc_0 done\n","fieldCount: 1 of 9 for image 0d4164_0 done\n","image 0bddf9_0 done!\n","image 0cc0bc_0 done!\n","fieldCount: 1 of 8 for image 0d533f_0 done\n","fieldCount: 1 of 4 for image 0d718a_0 done\n","fieldCount: 2 of 9 for image 0d4164_0 done\n","fieldCount: 2 of 4 for image 0d718a_0 done\n","fieldCount: 3 of 4 for image 0d718a_0 done\n","fieldCount: 4 of 4 for image 0d718a_0 done\n","image 0d718a_0 done!\n","fieldCount: 2 of 8 for image 0d533f_0 done\n","fieldCount: 3 of 9 for image 0d4164_0 done\n","fieldCount: 3 of 8 for image 0d533f_0 done\n","fieldCount: 4 of 8 for image 0d533f_0 done\n","fieldCount: 1 of 12 for image 0d93ce_0 done\n","fieldCount: 4 of 9 for image 0d4164_0 done\n","fieldCount: 5 of 8 for image 0d533f_0 done\n","fieldCount: 2 of 12 for image 0d93ce_0 done\n","fieldCount: 6 of 8 for image 0d533f_0 done\n","fieldCount: 7 of 8 for image 0d533f_0 done\n","fieldCount: 5 of 9 for image 0d4164_0 done\n","fieldCount: 8 of 8 for image 0d533f_0 done\n","fieldCount: 3 of 12 for image 0d93ce_0 done\n","image 0d533f_0 done!\n","fieldCount: 4 of 12 for image 0d93ce_0 done\n","fieldCount: 1 of 6 for image 0df5f8_0 done\n","fieldCount: 6 of 9 for image 0d4164_0 done\n","fieldCount: 5 of 12 for image 0d93ce_0 done\n","fieldCount: 2 of 6 for image 0df5f8_0 done\n","fieldCount: 7 of 9 for image 0d4164_0 done\n","fieldCount: 3 of 6 for image 0df5f8_0 done\n","fieldCount: 6 of 12 for image 0d93ce_0 done\n","fieldCount: 4 of 6 for image 0df5f8_0 done\n","fieldCount: 5 of 6 for image 0df5f8_0 done\n","fieldCount: 6 of 6 for image 0df5f8_0 done\n","fieldCount: 8 of 9 for image 0d4164_0 done\n","fieldCount: 7 of 12 for image 0d93ce_0 done\n","image 0df5f8_0 done!\n","fieldCount: 8 of 12 for image 0d93ce_0 done\n","fieldCount: 1 of 15 for image 0e4dac_0 done\n","fieldCount: 9 of 12 for image 0d93ce_0 done\n","fieldCount: 9 of 9 for image 0d4164_0 done\n","image 0d4164_0 done!\n","fieldCount: 10 of 12 for image 0d93ce_0 done\n","fieldCount: 2 of 15 for image 0e4dac_0 done\n","fieldCount: 1 of 3 for image 0e696a_0 done\n","fieldCount: 2 of 3 for image 0e696a_0 done\n","fieldCount: 3 of 3 for image 0e696a_0 done\n","fieldCount: 11 of 12 for image 0d93ce_0 done\n","fieldCount: 3 of 15 for image 0e4dac_0 done\n","fieldCount: 12 of 12 for image 0d93ce_0 done\n","image 0e696a_0 done!\n","fieldCount: 4 of 15 for image 0e4dac_0 done\n","fieldCount: 5 of 15 for image 0e4dac_0 done\n","image 0d93ce_0 done!\n","fieldCount: 1 of 2 for image 0ed87f_0 done\n","fieldCount: 2 of 2 for image 0ed87f_0 done\n","fieldCount: 1 of 2 for image 0e696a_1 done\n","image 0ed87f_0 done!\n","fieldCount: 2 of 2 for image 0e696a_1 done\n","fieldCount: 6 of 15 for image 0e4dac_0 done\n","image 0e696a_1 done!\n","fieldCount: 1 of 2 for image 0ed87f_1 done\n","fieldCount: 2 of 2 for image 0ed87f_1 done\n","fieldCount: 1 of 6 for image 0ee750_0 done\n","image 0ed87f_1 done!\n","fieldCount: 7 of 15 for image 0e4dac_0 done\n","fieldCount: 1 of 6 for image 0ee750_1 done\n","fieldCount: 2 of 6 for image 0ee750_0 done\n","fieldCount: 2 of 6 for image 0ee750_1 done\n","fieldCount: 3 of 6 for image 0ee750_0 done\n","fieldCount: 3 of 6 for image 0ee750_1 done\n","fieldCount: 8 of 15 for image 0e4dac_0 done\n","fieldCount: 9 of 15 for image 0e4dac_0 done\n","fieldCount: 4 of 6 for image 0ee750_1 done\n","fieldCount: 10 of 15 for image 0e4dac_0 done\n","fieldCount: 4 of 6 for image 0ee750_0 done\n","fieldCount: 5 of 6 for image 0ee750_1 done\n","fieldCount: 5 of 6 for image 0ee750_0 done\n","fieldCount: 6 of 6 for image 0ee750_1 done\n","fieldCount: 6 of 6 for image 0ee750_0 done\n","image 0ee750_1 done!\n","image 0ee750_0 done!\n","fieldCount: 11 of 15 for image 0e4dac_0 done\n","fieldCount: 12 of 15 for image 0e4dac_0 done\n","fieldCount: 1 of 9 for image 0fcfe9_0 done\n","fieldCount: 1 of 4 for image 0f2961_0 done\n","fieldCount: 2 of 4 for image 0f2961_0 done\n","fieldCount: 3 of 4 for image 0f2961_0 done\n","fieldCount: 4 of 4 for image 0f2961_0 done\n","fieldCount: 2 of 9 for image 0fcfe9_0 done\n","image 0f2961_0 done!\n","fieldCount: 13 of 15 for image 0e4dac_0 done\n","fieldCount: 14 of 15 for image 0e4dac_0 done\n","fieldCount: 15 of 15 for image 0e4dac_0 done\n","fieldCount: 1 of 6 for image 0ff6fc_0 done\n","image 0e4dac_0 done!\n","fieldCount: 3 of 9 for image 0fcfe9_0 done\n","fieldCount: 2 of 6 for image 0ff6fc_0 done\n","fieldCount: 1 of 3 for image 0ff890_0 done\n","fieldCount: 2 of 3 for image 0ff890_0 done\n","fieldCount: 4 of 9 for image 0fcfe9_0 done\n","fieldCount: 3 of 3 for image 0ff890_0 done\n","fieldCount: 3 of 6 for image 0ff6fc_0 done\n","image 0ff890_0 done!\n","fieldCount: 5 of 9 for image 0fcfe9_0 done\n","fieldCount: 4 of 6 for image 0ff6fc_0 done\n","fieldCount: 1 of 4 for image 112b6e_0 done\n","fieldCount: 5 of 6 for image 0ff6fc_0 done\n","fieldCount: 6 of 6 for image 0ff6fc_0 done\n","fieldCount: 6 of 9 for image 0fcfe9_0 done\n","image 0ff6fc_0 done!\n","fieldCount: 2 of 4 for image 112b6e_0 done\n","fieldCount: 7 of 9 for image 0fcfe9_0 done\n","fieldCount: 3 of 4 for image 112b6e_0 done\n","fieldCount: 1 of 8 for image 112b6e_1 done\n","fieldCount: 8 of 9 for image 0fcfe9_0 done\n","fieldCount: 4 of 4 for image 112b6e_0 done\n","image 112b6e_0 done!\n","fieldCount: 2 of 8 for image 112b6e_1 done\n","fieldCount: 9 of 9 for image 0fcfe9_0 done\n","image 0fcfe9_0 done!\n","fieldCount: 1 of 5 for image 113bb3_0 done\n","fieldCount: 2 of 5 for image 113bb3_0 done\n","fieldCount: 3 of 5 for image 113bb3_0 done\n","fieldCount: 4 of 5 for image 113bb3_0 done\n","fieldCount: 5 of 5 for image 113bb3_0 done\n","fieldCount: 3 of 8 for image 112b6e_1 done\n","fieldCount: 1 of 2 for image 129102_0 done\n","fieldCount: 2 of 2 for image 129102_0 done\n","image 113bb3_0 done!\n","image 129102_0 done!\n","fieldCount: 4 of 8 for image 112b6e_1 done\n","fieldCount: 5 of 8 for image 112b6e_1 done\n","fieldCount: 1 of 4 for image 12c8c9_0 done\n","fieldCount: 6 of 8 for image 112b6e_1 done\n","fieldCount: 1 of 3 for image 1295bb_0 done\n","fieldCount: 7 of 8 for image 112b6e_1 done\n","fieldCount: 2 of 3 for image 1295bb_0 done\n","fieldCount: 8 of 8 for image 112b6e_1 done\n","fieldCount: 3 of 3 for image 1295bb_0 done\n","fieldCount: 2 of 4 for image 12c8c9_0 done\n","image 112b6e_1 done!\n","image 1295bb_0 done!\n","fieldCount: 3 of 4 for image 12c8c9_0 done\n","fieldCount: 1 of 5 for image 140d1a_0 done\n","fieldCount: 2 of 5 for image 140d1a_0 done\n","fieldCount: 3 of 5 for image 140d1a_0 done\n","fieldCount: 1 of 18 for image 13f372_0 done\n","fieldCount: 4 of 5 for image 140d1a_0 done\n","fieldCount: 5 of 5 for image 140d1a_0 done\n","fieldCount: 4 of 4 for image 12c8c9_0 done\n","image 140d1a_0 done!\n","image 12c8c9_0 done!\n","fieldCount: 2 of 18 for image 13f372_0 done\n","fieldCount: 1 of 6 for image 14d2fa_0 done\n","fieldCount: 1 of 1 for image 15aab4_0 done\n","image 15aab4_0 done!\n","fieldCount: 3 of 18 for image 13f372_0 done\n","fieldCount: 4 of 18 for image 13f372_0 done\n","fieldCount: 5 of 18 for image 13f372_0 done\n","fieldCount: 6 of 18 for image 13f372_0 done\n","fieldCount: 2 of 6 for image 14d2fa_0 done\n","fieldCount: 1 of 4 for image 15de51_0 done\n","fieldCount: 7 of 18 for image 13f372_0 done\n","fieldCount: 3 of 6 for image 14d2fa_0 done\n","fieldCount: 2 of 4 for image 15de51_0 done\n","fieldCount: 4 of 6 for image 14d2fa_0 done\n","fieldCount: 5 of 6 for image 14d2fa_0 done\n","fieldCount: 3 of 4 for image 15de51_0 done\n","fieldCount: 6 of 6 for image 14d2fa_0 done\n","fieldCount: 8 of 18 for image 13f372_0 done\n","image 14d2fa_0 done!\n","fieldCount: 4 of 4 for image 15de51_0 done\n","image 15de51_0 done!\n","fieldCount: 1 of 8 for image 162cad_0 done\n","fieldCount: 9 of 18 for image 13f372_0 done\n","fieldCount: 10 of 18 for image 13f372_0 done\n","fieldCount: 2 of 8 for image 162cad_0 done\n","fieldCount: 11 of 18 for image 13f372_0 done\n","fieldCount: 12 of 18 for image 13f372_0 done\n","fieldCount: 1 of 2 for image 1764ff_0 done\n","fieldCount: 2 of 2 for image 1764ff_0 done\n","fieldCount: 13 of 18 for image 13f372_0 done\n","fieldCount: 3 of 8 for image 162cad_0 done\n","image 1764ff_0 done!\n","fieldCount: 4 of 8 for image 162cad_0 done\n","fieldCount: 5 of 8 for image 162cad_0 done\n","fieldCount: 14 of 18 for image 13f372_0 done\n","fieldCount: 1 of 2 for image 194e3f_0 done\n","fieldCount: 6 of 8 for image 162cad_0 done\n","fieldCount: 7 of 8 for image 162cad_0 done\n","fieldCount: 2 of 2 for image 194e3f_0 done\n","fieldCount: 8 of 8 for image 162cad_0 done\n","image 194e3f_0 done!\n","fieldCount: 15 of 18 for image 13f372_0 done\n","fieldCount: 16 of 18 for image 13f372_0 done\n","image 162cad_0 done!\n","fieldCount: 17 of 18 for image 13f372_0 done\n","fieldCount: 18 of 18 for image 13f372_0 done\n","image 13f372_0 done!\n","fieldCount: 1 of 8 for image 19b036_1 done\n","fieldCount: 1 of 4 for image 19dd95_0 done\n","fieldCount: 1 of 2 for image 19b036_0 done\n","fieldCount: 2 of 4 for image 19dd95_0 done\n","fieldCount: 2 of 8 for image 19b036_1 done\n","fieldCount: 2 of 2 for image 19b036_0 done\n","fieldCount: 3 of 4 for image 19dd95_0 done\n","image 19b036_0 done!\n","fieldCount: 4 of 4 for image 19dd95_0 done\n","fieldCount: 3 of 8 for image 19b036_1 done\n","image 19dd95_0 done!\n","fieldCount: 1 of 6 for image 1a2e9e_0 done\n","fieldCount: 4 of 8 for image 19b036_1 done\n","fieldCount: 5 of 8 for image 19b036_1 done\n","fieldCount: 6 of 8 for image 19b036_1 done\n","fieldCount: 2 of 6 for image 1a2e9e_0 done\n","fieldCount: 1 of 2 for image 1b86c5_0 done\n","fieldCount: 7 of 8 for image 19b036_1 done\n","fieldCount: 2 of 2 for image 1b86c5_0 done\n","fieldCount: 8 of 8 for image 19b036_1 done\n","image 1b86c5_0 done!\n","image 19b036_1 done!\n","fieldCount: 3 of 6 for image 1a2e9e_0 done\n","fieldCount: 1 of 4 for image 1d0518_0 done\n","fieldCount: 4 of 6 for image 1a2e9e_0 done\n","fieldCount: 1 of 3 for image 1bbcba_0 done\n","fieldCount: 5 of 6 for image 1a2e9e_0 done\n","fieldCount: 2 of 3 for image 1bbcba_0 done\n","fieldCount: 2 of 4 for image 1d0518_0 done\n","fieldCount: 6 of 6 for image 1a2e9e_0 done\n","fieldCount: 3 of 3 for image 1bbcba_0 done\n","image 1a2e9e_0 done!\n","image 1bbcba_0 done!\n","fieldCount: 3 of 4 for image 1d0518_0 done\n","fieldCount: 1 of 6 for image 1d1bf0_0 done\n","fieldCount: 1 of 2 for image 1d5335_0 done\n","fieldCount: 4 of 4 for image 1d0518_0 done\n","fieldCount: 2 of 2 for image 1d5335_0 done\n","fieldCount: 2 of 6 for image 1d1bf0_0 done\n","image 1d0518_0 done!\n","image 1d5335_0 done!\n","fieldCount: 1 of 6 for image 1db82d_0 done\n","fieldCount: 1 of 6 for image 1d6d4f_0 done\n","fieldCount: 2 of 6 for image 1db82d_0 done\n","fieldCount: 3 of 6 for image 1d1bf0_0 done\n","fieldCount: 2 of 6 for image 1d6d4f_0 done\n","fieldCount: 4 of 6 for image 1d1bf0_0 done\n","fieldCount: 3 of 6 for image 1db82d_0 done\n","fieldCount: 5 of 6 for image 1d1bf0_0 done\n","fieldCount: 6 of 6 for image 1d1bf0_0 done\n","fieldCount: 4 of 6 for image 1db82d_0 done\n","fieldCount: 5 of 6 for image 1db82d_0 done\n","fieldCount: 6 of 6 for image 1db82d_0 done\n","fieldCount: 3 of 6 for image 1d6d4f_0 done\n","fieldCount: 4 of 6 for image 1d6d4f_0 done\n","fieldCount: 5 of 6 for image 1d6d4f_0 done\n","fieldCount: 6 of 6 for image 1d6d4f_0 done\n","image 1d1bf0_0 done!\n","image 1d6d4f_0 done!\n","image 1db82d_0 done!\n"]}],"source":["#this cell executes the montecarlo samples and trains the final losslogevaluationmodel, which gets the the results of the montecarlo-predictions as input\n","from threading import Thread\n","from time import sleep\n","\n","class ImageProcessingThread(Thread):\n","    def __init__(self,imageId, evaluationFolder, numberOfSamplesPerImageField):\n","        Thread.__init__(self)\n","        self.imageId = imageId\n","        self.evaluationFolder = evaluationFolder\n","        self.numberOfSamplesPerImageField = numberOfSamplesPerImageField\n","        self.tileList = []\n","\n","    def run(self):\n","        self.tileList = imageSplittingAndTileGeneration(self.imageId, self.evaluationFolder , 'unknown', False, self.numberOfSamplesPerImageField)\n","\n","#create list of evaluations\n","evaluations = {} # key: image_id, value: output of [model1a, model1b, model2] times number of evaluations per image\n","#create list of random image tiles\n","randomImageTiles = []\n","numberOfSamplesPerImageField = 250\n","evaluationsPerImage = 48\n","\n","if trainingMode:\n","    evaluationFolder = trainingDataPathList[3]\n","    dataMetaTable = pd.read_csv('../input/mayo-clinic-strip-ai/train.csv')\n","    numberOfTrainingSamples = 128000\n","    accumulatedData = np.zeros(\n","    (numberOfTrainingSamples, evaluationsPerImage * 6), dtype=float)\n","    accumulatedLabels = np.zeros((numberOfTrainingSamples,numberOfClasses), dtype=float)\n","else:\n","    evaluationFolder = '../input/mayo-clinic-strip-ai/test/'\n","    dataMetaTable = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')\n","    #evaluationFolder = '../input/mayo-clinic-strip-ai/train/'\n","    #dataMetaTable = pd.read_csv('../input/mayo-clinic-strip-ai/test3.csv')\n","\n","def processImagesForEvaluation(): #each picture gets evaluated on the fly, results get saved in \"evaluations\", later the evaluations get combined in a final log-loss/cross-entropy model to a final result\n","    # iterate through the rows of the dataframe\n","    # ToDo refactor redundant code\n","    thread1 = None\n","    thread2 = None\n","    thread3 = None\n","    # added some multithreading experimantally to increase speed from 15 hours to under 9 hours on kaggle server\n","    for index, row in dataMetaTable.iterrows():\n","        # get the image id\n","        imageId = row['image_id']\n","        if os.path.exists(evaluationFolder + imageId + '.tif'):\n","            #get file size in byte\n","            fileSize = os.path.getsize(evaluationFolder + imageId + '.tif')\n","            currentImageGotThread = False\n","            while not currentImageGotThread:\n","                if thread1 == None:\n","                    thread1 = ImageProcessingThread(imageId, evaluationFolder, numberOfSamplesPerImageField)\n","                    currentImageGotThread = True\n","                    thread1.start()\n","                    continue #go to next image\n","                if thread2 == None:\n","                    thread2 = ImageProcessingThread(imageId, evaluationFolder, numberOfSamplesPerImageField)\n","                    currentImageGotThread = True\n","                    thread2.start()\n","                    continue #go to next image\n","                if thread3 == None:\n","                    thread3 = ImageProcessingThread(imageId, evaluationFolder, numberOfSamplesPerImageField)\n","                    currentImageGotThread = True\n","                    thread3.start()\n","                    continue\n","                # wait for one thread to finish\n","                while True:\n","                    sleep(0.1)\n","                    if thread1 == None or (not thread1.isAlive()):\n","                        break\n","                    if thread2 == None or (not thread2.isAlive()):\n","                        break\n","                    if thread3 == None or (not thread3.isAlive()):\n","                        break\n","                if thread1 != None and (not thread1.isAlive()):\n","                    predictAndWriteResult(thread1)\n","                    thread1 = None\n","                    continue\n","                if thread2 != None and (not thread2.isAlive()):\n","                    predictAndWriteResult(thread2)\n","                    thread2 = None\n","                    continue\n","                if thread3 != None and (not thread3.isAlive()):\n","                    predictAndWriteResult(thread3)\n","                    thread3 = None\n","                    continue\n","        else:\n","            print('image ' + imageId + ' does not exist')\n","    # wait for the last thread to finish\n","    while (thread1 != None and thread1.isAlive()) or (thread2 != None and thread2.isAlive() or (thread3 != None and thread3.isAlive())):\n","        sleep(0.1)\n","    if thread1 != None:\n","        predictAndWriteResult(thread1)\n","        thread1 = None\n","    if thread2 != None:\n","        predictAndWriteResult(thread2)\n","        thread2 = None\n","    if thread3 != None:\n","        predictAndWriteResult(thread3)\n","        thread3 = None\n","\n","def predictAndWriteResult(threadObject):\n","    tileList = threadObject.tileList\n","    imageId = threadObject.imageId\n","    if len(tileList) > 0:\n","        tilesToEvaluate = readRandomSamplesFromTileListForModel(tileList, evaluationsPerImage)\n","        evaluations[imageId] = predictTilesWithModels(tilesToEvaluate)\n","    print('image ' + imageId + ' done!')\n","\n","def readRandomSamplesFromTileListForModel(tileList, numberOfSamples):\n","    global randomImageTiles\n","    randomImageTiles.clear()\n","    for i in range(numberOfSamples):\n","        for j in range(numberOfInputImagesForOneModel):\n","            randomImageTiles.append(tileList[random.randint(0, len(tileList) - 1)])\n","    return randomImageTiles #returns a charge of image tiles to evaluate the image\n","\n","def predictTilesWithModels(listOfNDImagesToEvaluate):\n","    global evaluations\n","    #convert the list of numpy arrays to numpy array\n","    listOfNDImagesToEvaluate = np.array(listOfNDImagesToEvaluate, dtype=float)\n","    #get the ndarray with shape (numberOfSamples, 80, 80, 3) into the shape (numberOfSamples/numberOfInputImagesForOneModel,numberOfInputImagesForOneModel, 80, 80, 3)\n","    listOfNDImagesToEvaluate = listOfNDImagesToEvaluate.reshape((int(len(listOfNDImagesToEvaluate)/numberOfInputImagesForOneModel), numberOfInputImagesForOneModel, 80, 80, 3))\n","    #normalize the data 255\n","    listOfNDImagesToEvaluate *= 1.0 / 255.0\n","    # predict the tiles with the models\n","    model1aOutput = model1a.predict(listOfNDImagesToEvaluate)\n","    model1bOutput = model1b.predict(listOfNDImagesToEvaluate)\n","    model2Input = np.concatenate((model1aOutput, model1bOutput), axis=1)\n","    model2Output = model2.predict([listOfNDImagesToEvaluate, model2Input]).flatten()\n","    model1aOutput = model1aOutput.flatten()\n","    model1bOutput = model1bOutput.flatten()\n","    #make outputs one dimensional\n","    return np.concatenate((model1aOutput, model1bOutput, model2Output), axis=0)\n","\n","def loadTrainingData(): #creats and loads the montecarlo training data into accumulatedData and accumulatedLabels\n","    global evaluationFolder\n","    global accumulatedData\n","    global accumulatedLabels\n","    global numberOfTrainingSamples\n","    loadTrainingDataFolders(evaluationFolder)\n","    # load the data\n","    # iterate through the rows of the dataframe\n","    i = 0\n","    nextIsCE = True\n","    for i in range(numberOfTrainingSamples):\n","        # choose random image folder\n","        if nextIsCE:\n","            folder = random.choice(trainingDataFoldersCE)\n","        else:\n","            folder = random.choice(trainingDataFoldersLAA)\n","        tileList = [] #the list will contain NDArrays of the tiles\n","        for k in range(evaluationsPerImage):\n","            #choose random image\n","            for j in range(numberOfInputImagesForOneModel):\n","                imagePath = random.choice(trainingDataFoldersContent[folder])\n","                #load the image into the tileList using PIL\n","                image = Image.open(imagePath)\n","                image = np.array(image)\n","                tileList.append(image)\n","        predictions = predictTilesWithModels(tileList)\n","        accumulatedData[i] = predictions\n","        if nextIsCE:\n","            accumulatedLabels[i] = [1.0, 0.0]\n","        else:\n","            accumulatedLabels[i] = [0.0, 1.0]\n","        if i % 4000 == 3999:\n","            #save\n","            np.save('accumulatedData.npy', accumulatedData)\n","            np.save('accumulatedLabels.npy', accumulatedLabels)\n","            print('loaded ' + str(i + 1) + ' training samples')\n","        nextIsCE = not nextIsCE\n","            \n","def createFinalEvaluationLossLogModel(): #create a model that combines the evaluations of the models\n","    # create the model using functional Keras API\n","    inputLayer = keras.Input(shape=(evaluationsPerImage * 6,))\n","    layer1 = keras.layers.Dense(576, activation='relu')(inputLayer)\n","    layer2 = keras.layers.Dense(1152, activation='relu')(layer1)\n","    layer7 = keras.layers.Dense(576, activation='relu')(layer2)\n","    layer8 = keras.layers.Dense(144, activation='relu')(layer7)\n","    outputLayer = keras.layers.Dense(numberOfClasses, activation='softmax')(layer8)\n","    model = keras.Model(inputs=inputLayer, outputs=outputLayer)\n","    model.compile(\n","        optimizer=Adam(lr=0.0001),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy', 'categorical_crossentropy', 'categorical_accuracy']\n","    )\n","    return model\n","\n","def trainFinalEvaluationModel():\n","    global accumulatedData\n","    global accumulatedLabels\n","    # load the training data\n","    #check if the model exists, if not train it\n","    if os.path.isfile('finalLossLogEvaluationModel.h5'):\n","        return\n","    #check if accumulatedData.npy exists, if not load the data\n","    if os.path.isfile('accumulatedData.npy'):\n","        accumulatedData = np.load('accumulatedData.npy')\n","        accumulatedLabels = np.load('accumulatedLabels.npy')\n","        #reduce to numberOfSamples\n","        accumulatedData = accumulatedData[:numberOfTrainingSamples]\n","        accumulatedLabels = accumulatedLabels[:numberOfTrainingSamples]\n","    else:\n","        loadTrainingData()\n","        np.save('accumulatedData.npy', accumulatedData)\n","        np.save('accumulatedLabels.npy', accumulatedLabels)\n","    #create the model\n","    finalEvaluationModel = createFinalEvaluationLossLogModel()\n","    # train the final evaluation model using the fitst 126000 samples and validate using the other 2000 samples\n","    finalEvaluationModel.fit(accumulatedData[:126000], accumulatedLabels[:126000], epochs=16, batch_size=32, validation_data=(accumulatedData[126000:], accumulatedLabels[126000:]))\n","    # save the final evaluation model\n","    finalEvaluationModel.save('finalLossLogEvaluationModel.h5')\n","    \n","\n","if not trainingMode:\n","    processImagesForEvaluation()\n","else:\n","    trainFinalEvaluationModel()\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-10-05T13:32:40.564415Z","iopub.status.busy":"2022-10-05T13:32:40.563831Z","iopub.status.idle":"2022-10-05T13:32:41.481570Z","shell.execute_reply":"2022-10-05T13:32:41.480393Z","shell.execute_reply.started":"2022-10-05T13:32:40.564357Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["submission created!\n"]}],"source":["'''#test finalLossLogEvaluationModel.h5 on accumulatedDataTest.npy and accumulatedLabelsTest.npy\n","#load the test data\n","accumulatedDataTest = np.load('accumulatedDataTest.npy')\n","accumulatedLabelsTest = np.load('accumulatedLabelsTest.npy')\n","#load the model\n","finalEvaluationModel = keras.models.load_model('finalLossLogEvaluationModel.h5')\n","#evaluate the model\n","finalEvaluationModel.evaluate(accumulatedDataTest, accumulatedLabelsTest, batch_size=32, verbose=1)\n","result = finalEvaluationModel.predict(accumulatedDataTest[:50])\n","for i in range(50):\n","    print('label: ' + str(accumulatedLabelsTest[i]) + ' prediction: ' + str(result[i]))'''\n","if not trainingMode:\n","    finalEvaluationModel = keras.models.load_model(logLossEvaluationModelPath + 'finalLossLogEvaluationModel.h5')\n","    #dictionary to convert imageId to patientId\n","    imageIdToPatientId = {}\n","    #dictionary to convert patientId to list of score with number of images like [CE score, LAA score, numberOfImages]\n","    patientIdToScore = {}\n","    CE_INDEX = 0\n","    LAA_INDEX = 1\n","    NUMBER_OF_IMAGES_INDEX = 2\n","     #iterate through the rows of the dataframe and fill the dictionaries\n","    for index, row in dataMetaTable.iterrows():\n","        imageId = row['image_id']\n","        if row['patient_id'] not in patientIdToScore:\n","            patientIdToScore[row['patient_id']] = [0.0, 0.0, 0]\n","        # check if the dictionary \"evaluations\" is not None for image id\n","        if imageId in evaluations:\n","            toPredict = evaluations[imageId].reshape(1, evaluationsPerImage * 6)\n","            # predict the image\n","            result = finalEvaluationModel.predict(toPredict)\n","            currentScore = patientIdToScore[row['patient_id']]\n","            currentScore[CE_INDEX] += result[0][CE_INDEX]\n","            currentScore[LAA_INDEX] += result[0][LAA_INDEX]\n","            currentScore[NUMBER_OF_IMAGES_INDEX] += 1\n","\n","    #iterate through the patientIdToScore dictionary and calculate the average score\n","    patientIdGotScore = {}\n","    for index, row in dataMetaTable.iterrows():\n","        patientId = row['patient_id']\n","        currentScore = patientIdToScore[patientId]\n","        if patientId not in patientIdGotScore:\n","            if currentScore[NUMBER_OF_IMAGES_INDEX] != 0:\n","                currentScore[CE_INDEX] /= currentScore[NUMBER_OF_IMAGES_INDEX]\n","                currentScore[LAA_INDEX] /= currentScore[NUMBER_OF_IMAGES_INDEX]\n","            else:\n","                currentScore[CE_INDEX] = 0.5\n","                currentScore[LAA_INDEX] = 0.5\n","            patientIdGotScore[patientId] = True\n","    \n","    submission = pd.DataFrame(columns=['patient_id', 'CE', 'LAA'])\n","    for patientId in patientIdToScore:\n","        submission = submission.append({'patient_id': patientId, 'CE': patientIdToScore[patientId][CE_INDEX], 'LAA': patientIdToScore[patientId][LAA_INDEX]}, ignore_index=True)\n","    submission.to_csv('submission.csv', index=False)\n","    print('submission created!')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"vscode":{"interpreter":{"hash":"abc9fc88bc0e5c548c5da0f33af674c000293e7a58ee42428ace4cfa52bc0e99"}}},"nbformat":4,"nbformat_minor":4}
